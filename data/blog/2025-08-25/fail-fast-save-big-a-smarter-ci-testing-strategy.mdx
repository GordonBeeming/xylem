---
title: 'Fail Fast, Save Big: A Smarter CI Testing Strategy'
date: 2025-08-25
tags: ['DevOps', 'CI/CD', 'GitHub Actions', '.NET', 'Testing']
draft: false
summary: 'Our CI pipeline was burning through our budget and slowing developers down. The fix wasn''t about chasing raw speed, but about finding a better balance by handling failures more intelligently. Here''s how we did it.'
---

We've all been there. You get the dreaded notification: "You've nearly exhausted your GitHub Actions minutes for the month." ðŸ˜¬ For us, this was the final straw. Our CI pipeline felt slow, but the real problem was that it was expensive and inefficient, especially when builds failed.

The common instinct with DevOps is to chase raw speed. But when we dug in, we realized the true bottleneck wasn't the 'happy path' (a successful run), but how inefficiently we handled the much more common 'sad path' (a failed run). We needed a better balance.

This shift in thinking led us to a new strategy where our developers now get critical feedback in **under 3 minutes**, and we prevent our slow, expensive tests from ever running if a simple check fails.

## Context

Our system is a **modular monolith**, which has been great for development. However, it also meant that as our team added new modules, we kept adding new test projects. This happened organically over time until we looked up and realized we had **over 25 different test projects**.

Our old CI process for Pull Requests was what you might call "enthusiastically thorough" and hadn't kept pace with this growth. It ran everything all at once. When a developer pushed a commit, it kicked off a matrix of build jobs and another matrix of all 25+ of our test projectsâ€”unit and integration tests alikeâ€”in parallel.

On paper, running in parallel sounds fast. In reality, our build and test jobs would all kick off at the same time, mixing quick unit tests with our long-running integration tests. This created a few serious problems.

## The Problem: The High Cost of an Unbalanced Pipeline

This "all-at-once" approach was costing us dearly in three ways:

1.  **The Long Wait for Failure:** A developer had to wait over **7.5 minutes** (the time of our longest integration test) just to discover they'd broken a 30-second unit test. That's a long time to wait for simple feedback.
2.  **Wasted Money on Failed Builds:** This was the budget killer. When a quick unit test failed, our pipeline would still happily run all the other slow, expensive integration tests. We were literally paying for tests we already knew were pointless because the build was already broken.
3.  **Inefficiency Everywhere:** On top of everything, we weren't using caching effectively. Our Docker builds and NuGet dependency downloads were running from scratch every single time, making every job take longer and cost more than necessary.

## The Solution: A Strategy for Smarter Feedback

We decided to shift our focus from pure speed to intelligent feedback. The goal was to find a better balance that would get crucial information to developers faster and stop wasting money.

### 1. Tiered Testing: The Core of the Strategy

The hero of this story is tiered testing. We broke our monolithic test job into two dependent stages.

First, we run a `test-unit` job with only our fast unit tests.

```yaml
# .github/workflows/cicd.yml
jobs:
  test-unit:
    name: Run Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        testProject:
          - 'Tests/MyProject.UnitTests'
          - 'Tests/MyProject.Core.UnitTests'
    steps:
      # ... checkout, setup, etc.
      - name: Run ${{ matrix.testProject }}
        run: dotnet test ${{ matrix.testProject }}
````

Only if all unit tests pass do we proceed to the `test-integration` job.

```yaml
# .github/workflows/cicd.yml
  test-integration:
    name: Run Integration Tests
    runs-on: ubuntu-latest
    needs: test-unit # This is the magic line!
    strategy:
      matrix:
        testProject:
          - 'Tests/MyProject.Api.IntegrationTests'
          - 'Tests/MyProject.Database.IntegrationTests'
    steps:
      # ... checkout, setup, etc.
      - name: Run ${{ matrix.testProject }}
        run: dotnet test ${{ matrix.testProject }}
```

This `needs: test-unit` is the kill switch. If any unit test fails, the entire integration test stage is skipped, saving us time and a significant amount of money. This simple line creates a dependency graph in the workflow, making the intent clear even without a visual.

### 2\. Caching Dependencies

To reduce costs across the board, we implemented caching for NuGet packages. 

```yaml
# .github/workflows/cicd.yml
    steps:
    - name: Checkout repository
      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

    - name: Cache .NET packages
      uses: actions/cache@0400d5f644dc74513175e3cd8d07132dd4860809 # v4.2.4
      with:
        path: ~/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('Directory.Packages.props') }}
        restore-keys: |
          ${{ runner.os }}-nuget-

    # ... other steps
```

### 3\. Intelligent Docker Layering

Finally, we restructured our Dockerfiles to better leverage Docker's build cache. It's important to note that when we weren't caching our Docker layers, the order of the commands in the file didn't seem to matter much. However, **once you enable caching, the order becomes critical.**

The principle is to do the things that change least often first. This single change to our Dockerfiles dropped the image build time for a cached run from **9 minutes and 33 seconds** down to **7 minutes and 8 seconds**.

**Before:** We copied all our code *before* restoring dependencies, meaning any code change would invalidate the cache and trigger a slow `dotnet restore`.

```dockerfile
# Old Dockerfile (inefficient)
FROM mcr.microsoft.com/dotnet/sdk:9.0 AS build
WORKDIR /src
COPY . . # Copies everything at once
RUN dotnet restore "MyProject/MyProject.csproj" # Runs on every code change
# ...
```

**After:** We now copy only the `.csproj` files, restore the dependencies to create a stable cache layer, and *then* copy the rest of the source code.

```dockerfile
# New Dockerfile (efficient)
FROM mcr.microsoft.com/dotnet/sdk:9.0 AS build
WORKDIR /src

# Copy only project files first
COPY ["MyProject/MyProject.csproj", "MyProject/"]
COPY ["MyProject.Core/MyProject.Core.csproj", "MyProject.Core/"]

# This layer is now cached unless a dependency changes
RUN dotnet restore "MyProject/MyProject.csproj"

# Copy the frequently changing source code last
COPY . .
# ...
```

## The Payoff: A Smarter, Cheaper Feedback Loop

The results of these changes were fantastic, even if a little counter-intuitive.

  * **Feedback in Under 3 Minutes:** This is the headline win. Our developers now know if they've broken a core unit test in less than three minutes.
  * **Massive Cost Savings on Failure:** This solved our initial budget problem. If a PR fails the unit test stage, we save the cost and compute time of running **\~15 long integration tests**. This is even more significant when you remember that GitHub Actions bills by the minute; even if a skipped test would have only run for 5 seconds, we save a full billable minute for *each one*. For \~15 tests, that's a minimum of 15 saved minutes of compute on every failed run.
  * **The Perfect Trade-Off:** We made a deliberate trade-off.
      * The **wall-clock time** for a successful run (the time a developer waits) actually increased slightly, from \~7.5 minutes to \~10.5 minutes.
      * However, the **billable compute minutes** for that successful run **remain exactly the same**. We're running the same jobs, just in a smarter order.
      * Crucially, that extra \~3 minutes of waiting time is negligible in a real-world workflow. It's easily absorbed by the time a developer spends writing their PR description or reviewing their code. There is **no real-world productivity cost**.

It's the ideal outcome: we've gained huge savings on failed builds with no meaningful downside to developer time or our budget on successful ones.

## Final Thoughts

The biggest gains in CI efficiency don't always come from shaving seconds off a perfect run. For us, the real win came from striking a better balance. By intelligently handling failures *without negatively impacting the success path*, we created a cheaper, more efficient pipeline and a much better experience for our developers.

Take a look at your own pipelines. Are you paying a "failure tax"? You might find that the biggest improvements come not from chasing speed, but from building a smarter, more balanced process.